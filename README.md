### Code for our paper "[Classifying In-Place Gestures with End-to-End Point Cloud Learning](https://arxiv.org/abs/2108.09639)"

## Prerequisites

```
pytorch >= 1.7.1
scikit-learn == 0.24.1
tensorboardx == 2.2
```

## Experimental Dataset
Our dataset can be downloaded from [GoogleDrive](https://drive.google.com/drive/folders/1DmLEiakaXjjI0GILcHWifyEyJ3ysyWtu?usp=sharing).

## Model checkpoints
Models reported in our paper can be downloaded from [GoogleDrive](https://drive.google.com/drive/folders/1AkJTyt8ixpr6Oxt9iOk_9qBcMKw6izzf?usp=sharing).

## Reference
Code from [PCT](https://github.com/Strawberry-Eat-Mango/PCT_Pytorch) and [MCD](https://github.com/mil-tokyo/MCD_DA).

Thanks to the authors for contributing their code!



## Citation
If it is helpful for your work, please cite our paper
```
@misc{zhao2021classifying,
      title={Classifying In-Place Gestures with End-to-End Point Cloud Learning}, 
      author={Lizhi Zhao and Xuequan Lu and Min Zhao and Meili Wang},
      year={2021},
      eprint={2108.09639},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}
```
